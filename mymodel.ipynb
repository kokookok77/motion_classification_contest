{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train=pd.read_csv('train_features.csv')\n",
    "train_labels=pd.read_csv('train_labels.csv')\n",
    "test=pd.read_csv('test_features.csv')\n",
    "submission=pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'label' in train.columns:\n",
    "    train.drop(columns=['label'], inplace=True)\n",
    "train_total = pd.merge(train, train_labels, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_labels['label'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1875000"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "len(train_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1875000"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(train_labels)*600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "37 : 35\n",
      "37 : 455\n",
      "37 : 875\n",
      "37 : 1295\n",
      "37\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/aug/train_features_37.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b3832550a60b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'/aug/train_features_{label}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'/aug/train_labels_{label}.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             f, handles = get_handle(\n\u001b[0m\u001b[0;32m    186\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/aug/train_features_37.csv'"
     ]
    }
   ],
   "source": [
    "aug_cnt = 1400\n",
    "\n",
    "for idx, label in labels.iteritems():\n",
    "    tmps = train_total[train_total['label'] == label].copy()\n",
    "    while len(train_labels[train_labels['label'] == label]) < aug_cnt:\n",
    "        id_list = tmps['id'].drop_duplicates()\n",
    "        print(label,\":\", len(train_labels[train_labels['label'] == label]))\n",
    "        for idx, _id in id_list.iteritems():\n",
    "            if len(train_labels[train_labels['label'] == label]) < aug_cnt:\n",
    "                tmp = tmps[tmps['id'] == _id].copy()\n",
    "                tmp['acc_x'] = tmp['acc_x'] + tmp['acc_x'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                tmp['acc_y'] = tmp['acc_y'] + tmp['acc_y'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                tmp['acc_z'] = tmp['acc_z'] + tmp['acc_z'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                tmp['gy_x'] = tmp['gy_x'] + tmp['gy_x'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                tmp['gy_y'] = tmp['gy_y'] + tmp['gy_y'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                tmp['gy_z'] = tmp['gy_z'] + tmp['gy_z'].std() * np.random.normal(0.0, 1.0, 600)\n",
    "                newid = train['id'].max() + 1\n",
    "                tmp['id'] = newid\n",
    "                train = pd.concat([train, tmp])\n",
    "                train_labels = train_labels.append({'id': newid, 'label': label}, ignore_index=True)\n",
    "\n",
    "            if len(train_labels[train_labels['label'] == label]) < aug_cnt:\n",
    "                for rate in [0.1*i for i in range(5, 15)]:\n",
    "                    tmp = tmps[tmps['id'] == _id].copy()\n",
    "                    tmp['acc_x'] = tmp['acc_x']*rate\n",
    "                    tmp['acc_y'] = tmp['acc_y']*rate\n",
    "                    tmp['acc_z'] = tmp['acc_z']*rate\n",
    "                    tmp['gy_x'] = tmp['gy_x']*rate\n",
    "                    tmp['gy_y'] = tmp['gy_y']*rate\n",
    "                    tmp['gy_z'] = tmp['gy_z']*rate\n",
    "                    newid = train['id'].max() + 1\n",
    "                    tmp['id'] = newid\n",
    "                    train = pd.concat([train, tmp])\n",
    "                    train_labels = train_labels.append({'id': newid, 'label': label}, ignore_index=True)\n",
    "\n",
    "            if len(train_labels[train_labels['label'] == label]) < aug_cnt:\n",
    "                tmp = tmps[tmps['id'] == _id].copy()\n",
    "                tmp.sort_values(by='time', ascending=False)\n",
    "                newid = train['id'].max() + 1\n",
    "                tmp['id'] = newid\n",
    "                train = pd.concat([train, tmp])\n",
    "                train_labels = train_labels.append({'id': newid, 'label': label}, ignore_index=True)\n",
    "   \n",
    "    print(label)\n",
    "    train.to_csv(f'./aug/train_features_{label}.csv')\n",
    "    train_labels.to_csv(f'./aug/train_labels_{label}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = pd.DataFrame()\n",
    "train_label = pd.DataFrame()\n",
    "\n",
    "for _, label in labels.iteritems():\n",
    "    tmp_feature = pd.read_csv(f\"aug/train_features_{label}.csv\")\n",
    "    pd.concat([train_feature, tmp])\n",
    "\n",
    "    tmp_label = pd.read_csv(f\"aug/train_labels_{label}.csv\")\n",
    "    pd.concat([train_label, tmp])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.reshape(np.array(train_feature.iloc[:,2:]),[-1, 600, 6])\n",
    "print(X.shape)\n",
    "\n",
    "y=tf.keras.utils.to_categorical(train_label['label']) \n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_filters=32, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_filters = num_filters\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "\n",
    "    def _default_Conv1D(self, filters, kernal_size):\n",
    "        return tf.keras.layers.Conv1D(filters=filters,\n",
    "                                      kernal_size=kernal_size,\n",
    "                                      strides=1,\n",
    "                                      activation='relu',\n",
    "                                      use_bias=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        z_bottleneck = self._default_Conv1D(filters=self.num_filters, kernal_size=1)(inputs)\n",
    "        z_maxpool = tf.keras.layers.MaxPool1D(pool_size=3, strides=1, padding='same')(inputs)\n",
    "\n",
    "        z1 = self._default_Conv1D(filters=self.num_filters, kernel_size=10)(z_bottleneck)\n",
    "        z2 = self._default_Conv1D(filters=self.num_filters, kernel_size=20)(z_bottleneck)\n",
    "        z3 = self._default_Conv1D(filters=self.num_filters, kernel_size=40)(z_bottleneck)\n",
    "        z4 = self._default_Conv1D(filters=self.num_filters, kernel_size=1)(z_maxpool)\n",
    "\n",
    "        z = tf.keras.layers.Concatenate(axis=2)([z1, z2, z3, z4])\n",
    "        z = tf.keras.layers.BatchNormalization()(z)\n",
    "\n",
    "        return self.activation(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortcut_layer(inputs, z_inception):\n",
    "    z_shortcut = tf.keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), \n",
    "                                        kernel_size=1, \n",
    "                                        padding='same', \n",
    "                                        use_bias=False)(inputs)\n",
    "\n",
    "    z_shortcut = tf.keras.layers.BatchNormalization()(z_shortcut)\n",
    "\n",
    "    z = keras.layers.Add()([z_shortcut, z_inception])\n",
    "\n",
    "    return tf.keras.layers.Activation('relu')(z)\n",
    "\n",
    "\n",
    "def build_model(input_shape, num_classes, num_modules=6):\n",
    "    input_layer = tf.keras.layers.Input(input_shape)\n",
    "    z = input_layer\n",
    "    z_residual = input_layer\n",
    "\n",
    "    for i in range(num_modules):\n",
    "        z = InceptionModule()(z)\n",
    "        if i%3 == 2:\n",
    "            z = shortcut_layer(z_residual, z)\n",
    "            z_residual = z\n",
    "\n",
    "    gap_layer = tf.keras.layers.GlobalAveragePooling1D()(z)\n",
    "    output_layer = tf.keras.layers.Dense(num_classes, activation='softmax')(gap_layer)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs= input_layer, outputs= output_layer)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  }
 ]
}